server:
  port: 9080
  servlet:
    context-path: /v1

spring:
  application:
    name: sb-eda-kafka

  kafka:
    bootstrap-servers: ${BOOTSTRAP_SERVERS:minikube:31335,minikube:32604,minikube:30446}
    admin:
      properties:
        request.timeout.ms: 3000
        default.api.timeout.ms: 3000
    properties:
      security.protocol: SASL_PLAINTEXT
      sasl.mechanism: SCRAM-SHA-256
      sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username="user1" password="dmWhpQuo15";
      schema.registry.url: ${SCHEMA_REGISTRY_URL:http://minikube:30081}
      specific.avro.reader: true
      enable.auto.commit: false
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      acks: ${ACKS:all}
#    consumer:
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
#      group-id: event-consumers
#      client-id: ${HOSTNAME:sb-eda-kafka}
#      auto-offset-reset: earliest
#    listener:
#      ack-mode: manual
#    retry:
#      topics:
#        enabled: true

management:
  endpoints:
    web:
      exposure:
        include: health, info
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
      group:
        readiness:
          include: readinessState,kafka

springwolf:
  docket:
    base-package: com.example.eda.service
    info:
      title: ${spring.application.name}
      version: 1.0.0
    servers:
      kafka-server:
        protocol: kafka
        host: ${kafka.bootstrap.servers}

messaging:
  topic:
    name: event-stream
